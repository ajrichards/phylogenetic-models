{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In science we carry out the iterative process of updating our belief in a conclusion each time we have new evidence.  In the fields of science that focus on experiments it is not difficult to argue that we are constantly updating our belief about one thing or another.  However, in statistics it is often that case that we completely ignore any belief that we might have.  Under a the Bayesian paradigm and when feasible relevant data can and should be used to update our degree of belief.  Then once we aquire more data we should again be updating our degree of belief.  If $N$ is very large the Bayesian and Frequentist results will be nearly identical.\n",
      "\n",
      "In the toolbox of methods that exist for data analysis sometimes it is a Bayesian tool and sometimes it is a frequentist one that is best fit for solving a particular problem.  The discussion then should not be about better or worse rather which is a more appropriate tool for that particular job at hand.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "2+2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "LaTeX: \\alpha^2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}